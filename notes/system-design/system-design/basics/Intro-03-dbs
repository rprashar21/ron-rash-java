rdbms - acid
Atomicity - Each transaction is all or nothing
Consistency - Any transaction will bring the database from one valid state to another
Isolation - Executing transactions concurrently has the same results as if the transactions were executed serially
Durability - Once a transaction has been committed, it will remain so

Techniques to scale a relational database:

master-slave replication, clinet can onlyread/write to master -- clinet can only read from replications
master-master replication,

federation -like each microservice have its own db,splits up databases by function like users db products db
there will be less read and write ,less memory
cons - comllex queries joins

sharding - distributes data across different databases, each db manages a subset of db
Taking a users database as an example, as the number of users increases, more shards are added to the cluster.

| Feature         | Partitioning                                                                         | Sharding                                                                        |
| --------------- | ------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------- |
| ðŸŽ¯ Definition   | Splitting data **within a single database system** into smaller pieces (partitions). | Splitting data **across multiple independent databases or nodes**.              |
| ðŸ§© Scope        | Logical or physical, still under same DB instance                                    | Horizontal scaling by distributing across **nodes/servers**                     |
| ðŸ› ï¸ Managed By  | Mostly **DB engine itself** (e.g., PostgreSQL partitioning)                          | Often **application or sharding middleware** (e.g., Cassandra, MongoDB, Vitess) |
| ðŸ“ˆ Use Case     | Improve **query performance** and **manageability** within large tables              | Improve **scalability** and **write/read throughput** for very large datasets   |
| ðŸ’¥ Failure Mode | All partitions still live in one system â†’ **single point of failure**                | Nodes can fail independently â†’ **resilience** but requires orchestration        |

Partitioning: Breaking a table into smaller pieces inside one large cupboard (database).
Sharding: Putting each piece of data in a different cupboard in different rooms (servers or DBs).


Partition -- big table broken into small tables
Simple exmaple -- u have an application where u log details in an audit log, the tbale has a field called log_date
expectation are say appp like github or gitlab where 100 millions users are performing operations
1 million logs/hour
Need to retrieve last 1,000 events for any user within 100ms

CREATE TABLE audit_logs PARTITION BY RANGE (log_date);
-- Create monthly partitions -- we can alos create weekly partitions with some  data retention and then archive the data
CREATE TABLE audit_logs_202509 PARTITION OF audit_logs FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

when we do partitioning the database it self will automtically logically like folder structure group the data based on our partitions
we do not have to handle that ,, -- we can query directly from the partitions
application query can be ffrom a range this will improve performance


Advantages
simpler setup ,same db instance, eg PostgreSQL query planner supports partition elimination
cons -- poor scalling ,less vertical scalling,single point of fauilure

==================
Sharding -- Putting huge amounts of data ins separate db servers
good scaling , but complexx queries, difficult manages

Use Apache Cassandra (or a sharding middleware like Vitess over MySQL).
Partition key = user_id
Clustering key = event_time DESC -Fast inserts (append-only log pattern)
High availability: failure of 1 node doesnâ€™t take down the cluster

NFR comparsin between partitioning and Sharding

| Requirement         | Partitioning                      | Sharding                                 |
| ------------------- | --------------------------------- | ---------------------------------------- |
| **Scalability**     | Medium (vertical)                 | High (horizontal)                        |
| **Latency**         | Low                               | Low to medium (depends on key design)    |
| **Availability**    | Medium (1 node failure = DB down) | High (node redundancy)                   |
| **Maintainability** | Easy (fewer moving parts)         | Complex (cluster management)             |
| **Cost**            | Low (single server)               | High (multi-node infra, DevOps, backups) |


Summary
Partitioning is ideal when I want better query performance over large datasets within a single database.
But for write-heavy systems or global-scale workloads like user logs, IoT events, or metrics,
I prefer sharding using distributed databases like Cassandra or a middleware like Vitess.
Sharding brings cost and complexity, but it enables horizontal scale and resilience.
I always evaluate based on NFRs: expected data size, query latency, availability targets, and operational readiness of the team.â€

Bsically partition u split tables within a single db and that db has a single engine
whereas in sharding u actually spit dat into multiple dbs

This is true sharding -->
Now imagine you split logs by region:
EU data goes to audit_logs_eu@db-eu.example.com
US data goes to audit_logs_us@db-us.example.com
Your application decides where to write/read based on region â€” this is true sharding.

Partitioning means dividing a table within a single database system, usually managed by the same query planner and engine.
It improves performance and maintainability without distributing data across multiple database instances.
However, you can still use read replicas and HA setups alongside partitioning â€” they donâ€™t conflict.

Sharding, on the other hand, distributes the data across multiple independent database nodes,
typically requiring application-level routing or a sharding middleware


cons -> complexity
 A sharding function based on consistent hashing can reduce the amount of transferred data


denormalization,
SQL tuning.
In SQL-based systems, performance starts with designing for access patternsâ€”then tuning indexes,
caching, and partitions accordingly. For large-scale systems, I think in terms of query shape, hot paths, and how reads and writes scale differently.
I measure before optimizing and always watch for slow queries and unnecessary joins.
Tuning is less about magic and more about observability and practical trade-offs
indexs -- use proper indexes -- indexs can hurt perfromance
use proper queries ,fetch only columns wnated
Use EXPLAIN or query plan analysis to identify full table scans or bad indexes.
Do proper partition and sharding , partition large tables by time, tenant, or status to reduce I/O.
rewrite expensive queries , caching layer,Handle Large Data Sets Carefully{bulk updates and writes }
schema tuning - use apporaproate data types -- ,

monitoring and observabiltity
Log and track slow queries.
Monitor key DB metrics: CPU, IOPS, query time, connection pool, buffer pool hit rate.
Use APM tools (e.g., New Relic, Datadog) to track query performance in context

We used EXPLAIN ANALYZE to understand why our queries werenâ€™t using indexes.â€
â€œWe chose to denormalize X table due to frequent JOINs causing high latency.â€
â€œWe cached the first page of results in Redis with a short TTL and fall back to DB for deep pagination.â€
â€œWe used read replicas for 90% of our query traffic to protect the primary from overload.â€
â€œWe moved time-series logs to partitioned tables to optimize recent data access.

COnnection pooling, optimie queries ,

example of e used EXPLAIN ANALYZE to understand why our queries werenâ€™t using indexes
Actula Query
SELECT * FROM products
WHERE category = 'electronics'
AND available = true
ORDER BY updated_at DESC
LIMIT 20;

analyzing --> EXPLAIN ANALYZE SELECT * FROM ...

Finding:

The output showed "Using filesort" and "Full Table Scan"
Reason: the query wasnâ€™t using the index effectively because the index didnâ€™t match the filter + sort order

created a composite index
CREATE INDEX idx_category_avail_updated
ON products(category, available, updated_at DESC);

FOr partition example
A system recorded audit logs (e.g., user actions). Queries to recent logs were fast, but scans or filters across the full table were very slow.
SELECT * FROM audit_logs
WHERE timestamp > NOW() - INTERVAL 1 DAY
ORDER BY timestamp DESC;

Problem
Table had 500M+ rows
No pruning or filtering
Even LIMIT queries scanned large portions of the table


Solution: Partition by Date -Recreated audit_logs with partitioning by month
CREATE TABLE audit_logs (
  id BIGINT,
  user_id INT,
  action VARCHAR(255),
  timestamp DATETIME,
  ...
) PARTITION BY RANGE (YEAR(timestamp) * 100 + MONTH(timestamp)) (
  PARTITION p202501 VALUES LESS THAN (202502),
  PARTITION p202502 VALUES LESS THAN (202503),
  ...
);

-----
Nosql is collection of data in key value or documnets trore or wide column store, or a graph database
data is denormalized ,joins are generally done in the application code
lacks acid favors eventual consistency

BASE is often used to describe the properties of NoSQL databases
bascalill the syetm is alwasy availabe, eventual consistent, the system may change over time

Which type of no sql best fits ur solution keyvalue,document,wide column store,graph databse
KeyValue store -- hash table , high performacne , o(1) read and write, simple mode complexity is shifted to application layer
mostly for caching
Redis (in-memory, also supports expiry & data structures)
Amazon DynamoDB (can behave as key-value with primary key access)
We used Redis as a key-value cache to store the first 10 products of each category page for fast delivery and reduced DB pressure

Document Store- we store semi structured json like documnets
Each document can have its own schema
Allows nested objects, arrays, and hierarchical data

schema flexibilty--
We stored blog posts and comments in MongoDB since each post had flexible structure, tags, embedded media, and varying fields per use

Wide-Column Store - Apache Cassandra
Stores data in rows and dynamic columns, grouped in column families
When to use:
Massive-scale write-heavy workloads (IoT, metrics, event logs)
Time-series data, user activity logs, recommendation engines
Great for horizontal partitioning (sharding)
Designed to write and read in chunks efficiently
Column-level tuning possible (e.g., TTL, compression)


| Type            | Best For                        | Querying Style        | Example Use Case                       |
| --------------- | ------------------------------- | --------------------- | -------------------------------------- |
| **Key-Value**   | Fast lookup by key              | Get(key)              | Caching, sessions, rate limiting       |
| **Document**    | Flexible, nested data           | Query by fields       | User profiles, blog posts, e-commerce  |
| **Wide-Column** | Time-series, large scale writes | Filter on keys/ranges | IoT data, logs, recommendation engines |
| **Graph**       | Relationship-heavy data         | Node/edge traversal   | Social graphs, fraud detection         |
